{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvUc/7Plkci4D3brCu+kEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahidmb/DL/blob/main/Simple_Classification_wit_FL_on_Cifar10_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Classification wit FL on Cifar10 dataset\n"
      ],
      "metadata": {
        "id": "tgA2hhpfjj_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdTE8D1mjhS0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "VCTOSVlXloVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf4c581-6c34-4303-b4b6-4cab919f4f24",
        "id": "i6jY-QF0jhS1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# # Make sure images have shape (28, 28, 1)\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHQGNKI3gSQG",
        "outputId": "af400eb3-e5b5-4f80-cc16-c4ca0af2a2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting training data for multiple clients"
      ],
      "metadata": {
        "id": "TDggc1VRkLwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_splits = np.array_split(x_train,4)\n",
        "y_train_splits = np.array_split(y_train,4)"
      ],
      "metadata": {
        "id": "g6VDJIg7kJjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_splits[1].shape\n",
        "# len(x_train_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4V82cFhlIj_",
        "outputId": "fef59788-9116-485e-e1b1-a3b91cce336e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Designing"
      ],
      "metadata": {
        "id": "IwByDoZXlw7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSGy6HihjhS3"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=input_shape),\n",
        "          layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Flatten(),\n",
        "          layers.Dropout(0.5),\n",
        "          layers.Dense(num_classes, activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # model.summary()\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating multiple clients (models)"
      ],
      "metadata": {
        "id": "8iMWvF4zl4y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1 = create_model()\n",
        "# model_1.summary()\n",
        "model = []\n",
        "for i in range(4):\n",
        "  model.append(create_model())\n",
        "  # model_i.summary()\n",
        "  # print(i)"
      ],
      "metadata": {
        "id": "3pezpV1BmCkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model[3].summary()"
      ],
      "metadata": {
        "id": "6FBPUJDgu0re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling models"
      ],
      "metadata": {
        "id": "DvkQnY2_xN-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "  model[i].compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "vIHM7c_fxUel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training models"
      ],
      "metadata": {
        "id": "pa9NE6n6xmOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqltW9eFjhS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b835f322-c1b7-45be-d23b-2e282996342f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 0 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 2s 14ms/step - loss: 2.0024 - accuracy: 0.2730 - val_loss: 1.7265 - val_accuracy: 0.3985\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6680 - accuracy: 0.3997 - val_loss: 1.5712 - val_accuracy: 0.4458\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.5389 - accuracy: 0.4486 - val_loss: 1.4590 - val_accuracy: 0.4907\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4435 - accuracy: 0.4905 - val_loss: 1.3883 - val_accuracy: 0.5157\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3771 - accuracy: 0.5161 - val_loss: 1.3451 - val_accuracy: 0.5228\n",
            "Training 1 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 3s 12ms/step - loss: 2.0101 - accuracy: 0.2678 - val_loss: 1.7295 - val_accuracy: 0.3914\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6822 - accuracy: 0.3966 - val_loss: 1.5603 - val_accuracy: 0.4435\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.5524 - accuracy: 0.4512 - val_loss: 1.4891 - val_accuracy: 0.4684\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4502 - accuracy: 0.4819 - val_loss: 1.4497 - val_accuracy: 0.4895\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3881 - accuracy: 0.5082 - val_loss: 1.3584 - val_accuracy: 0.5229\n",
            "Training 2 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 2s 13ms/step - loss: 2.0310 - accuracy: 0.2553 - val_loss: 1.7461 - val_accuracy: 0.3859\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6967 - accuracy: 0.3957 - val_loss: 1.6098 - val_accuracy: 0.4191\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5503 - accuracy: 0.4376 - val_loss: 1.4718 - val_accuracy: 0.4821\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4731 - accuracy: 0.4735 - val_loss: 1.4110 - val_accuracy: 0.4999\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.4055 - accuracy: 0.5027 - val_loss: 1.3721 - val_accuracy: 0.5222\n",
            "Training 3 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 2s 13ms/step - loss: 1.9953 - accuracy: 0.2783 - val_loss: 1.6812 - val_accuracy: 0.4051\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6327 - accuracy: 0.4135 - val_loss: 1.5077 - val_accuracy: 0.4703\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5011 - accuracy: 0.4639 - val_loss: 1.4342 - val_accuracy: 0.4901\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.4222 - accuracy: 0.4962 - val_loss: 1.3749 - val_accuracy: 0.5122\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3767 - accuracy: 0.5157 - val_loss: 1.3315 - val_accuracy: 0.5373\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 5\n",
        "for i in range(4):\n",
        "  print(\"Training %s model :\" % (i))\n",
        "  model[i].fit(x_train_splits[i], y_train_splits[i], validation_data=(x_test, y_test), batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# model[0].fit(x_train_splits[0], y_train_splits[0], validation_data=(x_test, y_test), batch_size=batch_size, epochs=epochs)\n",
        "# model[1].fit(x_train_splits[1], y_train_splits[1], validation_data=(x_test, y_test), batch_size=batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bf0452-4910-43ab-e6f0-345d8418c964",
        "id": "PyqPqFWxjhS4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.3531177043914795\n",
            "Test accuracy: 0.5239999890327454\n"
          ]
        }
      ],
      "source": [
        "\n",
        "score = model[0].evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking aggregation"
      ],
      "metadata": {
        "id": "U5dLNiy00HGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(4):\n",
        "\n",
        "  predictions.append(model[i].predict(x_test))\n",
        "\n",
        "\n",
        "# predictions[0]"
      ],
      "metadata": {
        "id": "5wfpOKCt0L7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de63953-feaf-4698-fd31-043ec06880bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# w = model[0].get_layer(\"dense\").get_weights()[0] # weights\n",
        "w0 = model[0].get_weights()\n",
        "w1 = model[1].get_weights()\n",
        "w2 = model[2].get_weights()\n",
        "w3 = model[3].get_weights()"
      ],
      "metadata": {
        "id": "0nzmD1WQXWJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise_dist = np.vstack((w0,w1,w2,w3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ3_WJq6dzdd",
        "outputId": "1b82e70e-f6f2-4be5-ac59-db3f68b5c54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ary = asanyarray(ary)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_w = np.average(pairwise_dist,axis=0)\n",
        "avg_w[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLvdplQYeZKS",
        "outputId": "693f8f46-ce47-4da9-df17-443d6bfe3661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3, 3, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Code"
      ],
      "metadata": {
        "id": "EFNOnn-Em3Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "#Splitting training data for multiple clients\n",
        "x_train_splits = np.array_split(x_train,4)\n",
        "y_train_splits = np.array_split(y_train,4)\n",
        "\n",
        "\n",
        "#Model Designing\n",
        "def create_model():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=input_shape),\n",
        "          layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Flatten(),\n",
        "          layers.Dropout(0.5),\n",
        "          layers.Dense(num_classes, activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # model.summary()\n",
        "  return model\n",
        "\n",
        "# Creating multiple clients (models)\n",
        "model = []\n",
        "for i in range(4):\n",
        "  model.append(create_model())\n",
        "\n",
        "# Compiling models\n",
        "for i in range(4):\n",
        "  model[i].compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Training models\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "for i in range(4):\n",
        "  print(\"Training %s model :\" % (i))\n",
        "  model[i].fit(x_train_splits[i], y_train_splits[i], validation_data=(x_test, y_test), batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Taking aggregation\n",
        "w0 = model[0].get_weights()\n",
        "w1 = model[1].get_weights()\n",
        "w2 = model[2].get_weights()\n",
        "w3 = model[3].get_weights()\n",
        "\n",
        "pairwise_dist = np.vstack((w0,w1,w2,w3))\n",
        "\n",
        "avg_w = np.average(pairwise_dist,axis=0)\n",
        "\n",
        "print(\"Average weights:\")\n",
        "avg_w.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aSKeY_Dm22x",
        "outputId": "45a0766e-60e7-41cb-8474-ee2a66338790"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Training 0 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 6s 16ms/step - loss: 2.0033 - accuracy: 0.2722 - val_loss: 1.7271 - val_accuracy: 0.3846\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6513 - accuracy: 0.4144 - val_loss: 1.5955 - val_accuracy: 0.4355\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.5201 - accuracy: 0.4538 - val_loss: 1.4746 - val_accuracy: 0.4798\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4402 - accuracy: 0.4822 - val_loss: 1.4012 - val_accuracy: 0.5068\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3875 - accuracy: 0.5091 - val_loss: 1.3792 - val_accuracy: 0.5172\n",
            "Training 1 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 2s 14ms/step - loss: 2.0045 - accuracy: 0.2698 - val_loss: 1.7378 - val_accuracy: 0.3896\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.6745 - accuracy: 0.4086 - val_loss: 1.5811 - val_accuracy: 0.4395\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5379 - accuracy: 0.4473 - val_loss: 1.4628 - val_accuracy: 0.4848\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4490 - accuracy: 0.4852 - val_loss: 1.3880 - val_accuracy: 0.5088\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3802 - accuracy: 0.5128 - val_loss: 1.3335 - val_accuracy: 0.5323\n",
            "Training 2 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 2s 14ms/step - loss: 1.9880 - accuracy: 0.2813 - val_loss: 1.7198 - val_accuracy: 0.3879\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6892 - accuracy: 0.3938 - val_loss: 1.5745 - val_accuracy: 0.4356\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.5574 - accuracy: 0.4412 - val_loss: 1.4726 - val_accuracy: 0.4747\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4729 - accuracy: 0.4722 - val_loss: 1.4154 - val_accuracy: 0.5008\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4053 - accuracy: 0.5015 - val_loss: 1.3878 - val_accuracy: 0.5126\n",
            "Training 3 model :\n",
            "Epoch 1/5\n",
            "98/98 [==============================] - 2s 13ms/step - loss: 1.9947 - accuracy: 0.2775 - val_loss: 1.6968 - val_accuracy: 0.3838\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6507 - accuracy: 0.4086 - val_loss: 1.5538 - val_accuracy: 0.4392\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5254 - accuracy: 0.4530 - val_loss: 1.4460 - val_accuracy: 0.4940\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4498 - accuracy: 0.4789 - val_loss: 1.3996 - val_accuracy: 0.5069\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4134 - accuracy: 0.5052 - val_loss: 1.3462 - val_accuracy: 0.5337\n",
            "Average weights:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ary = asanyarray(ary)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}